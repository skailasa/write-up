\documentclass[12pt, a4]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}

\usepackage[backend=bibtex]{biblatex}
\addbibresource{dist.bib}

\title{Linear Partial Differential Equations}
\author{Srinath Kailasa \thanks{srinath.kailasa.18@ucl.ac.uk} \\ \small University College London}

\date{\today}



\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{notation}{Notation}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{problem}[theorem]{Problem}

\DeclareMathOperator\supp{supp}
\DeclareMathOperator\reals{\mathbb{R}}
\DeclareMathOperator\complexes{\mathbb{C}}
\DeclareMathOperator\tfspace{C_0^\infty}
\DeclareMathOperator\tfspaceD{\mathcal{D}}
\DeclareMathOperator\dist{\mathcal{D'}}
\DeclareMathOperator\lone{L_{\text{loc}}^1}
\begin{document}

\maketitle

\section*{Abstract}

In this document I summarise some of the main applications of the theory of distributions for the solution of partial differential equations via the method of `fundamental solutions'. I begin by introducing the key concepts behind the idea of the method of distributions, with the goal of solving the Laplace and Heat equations using these ideas. We proceed to an overview of the Fourier transform, and its usage for solving PDEs, and its description within the theory of distributions. We conclude with a soujourn on Sobolev spaces, and a short description of their utility in extending weak solutions, derived using distribution theory, to full classical solutions of PDEs. Furthermore, this document also includes a `scratch pad' section, in which I provide further examples and proofs of the applications of these ideas.

\section{Distributions and Test Functions}

\subsection{Motivation}

Consider the wave equation in 1D,

\begin{equation}
    \frac{\partial^2u(x, t)}{\partial t^2} = \frac{\partial^2u(x, t)}{\partial x^2}
    \label{eq:wave_eq_1d}
\end{equation}

Any twice continuosly differentiable function $f \in C^2(\reals)$ of the form $u(x, t) = f(x-t)$ satisfies the wave equation. However, we face difficulties if the solution is admissable in a physical sense, but has mathematical problems such as being non-continuous, e.g. $u(x, t) = |x-t|$. This is the motivation behind seeking a new theory, a theory of distributions, which allow us to generalise notions of derivatives and solve problems with solutions that may not not be mathematicallly particlarly `nice' as they may be required by the physics of the problem. These generalisations are known as distributions.

\subsection{Defining Test Functions}

A few basic definitions will serve us well for the remainder of these notes.

\begin{definition}[Classes of Continuous Functions]
Let $\Omega^N$ be an open subset and let $m$ be a non-negative integer. The class $C^m(\Omega)$ consists of functions on $\Omega$ which have continuous derivatives of order less than or equal to $m$. Furthermore (1) $C^0(\Omega) = C(\Omega)$  is simply the class of all continuous functions on $\Omega$ and (2) $C^\infty (\Omega)$ is the class of functions with derivatives of all orders.
\label{def:c_m_functions}
\end{definition}

\begin{definition}[Support of Functions]
The support of a function $f : \Omega \rightarrow \mathbb{C}$ is the closure of the set $\{x \in \Omega | f(x) \neq 0\}$
\[ \supp f = \overline{\{x \in \Omega | f(x) \neq 0\}}\]
\label{def:support_of_functions}
\end{definition}

Examples in $\Omega = \reals$

\begin{itemize}
    \item $f(x) = 0$, then  $\supp f = \emptyset$
    \item $f(x) = x$, then $\supp f = \reals$
\end{itemize}

\begin{definition}
    $C_0^\infty(\reals^N)$ is the subset of $C^\infty(\reals^N)$ consisting of functions with \textbf{compact} support.
\end{definition}

\begin{definition}[Compact]
    Compact in this context means a \textbf{closed} and \textbf{bounded} set.
    \[ \Omega \subset \reals^N\]
    is bounded if $\exists R > 0$ such that
    \[\Omega \subset B_R = \{ x : |x| < R\}\]
    and $|x|$ can be understood as a length in $\reals^N$.
    \label{def:compact_function}
\end{definition}

Now we list some of the basic properties of the function space described by $\tfspace$, as this is the space from which we seek our coveted test functions. We can think of it as a linear vector space, with the usual properties. That is, for $\phi_1, \phi_2 \in \tfspace$ and $\alpha_1, \alpha_2 \in \complexes$,

\begin{eqnarray}
    \alpha_1\phi_1 + \alpha_2\phi_2  \in \tfspace
\end{eqnarray}

Before arriving at the final definition of test functions, we must also introduce the concept of the multi-index. This has a familiar whiff about if for those who are familiar with vector-calculus.

\begin{notation}[Multi-Index]
    A multi-index is a vector with $N$ components, \[ \alpha=(\alpha_1,...,\alpha_N) \] where each component is a non-negative integer. It has an \textbf{order}, described by the sum of all components $|\alpha| = \alpha_1+...+\alpha_N$. If $\beta$ is also a multi-index, then $\alpha+\beta$ is a component-wise sum.
\end{notation}

Using multi-indices we can denote the derivative of a function $f(x_1,x_2,...)$ with respect to a multi-index as,

\begin{eqnarray}
    \partial^\alpha f = \frac{\partial^{|\alpha|}}{\partial x_1^{\alpha_1}, \partial x_2^{\alpha_2}, ..., \partial x_N^{\alpha_N}}
\end{eqnarray}

Furthermore, for $\phi \in \tfspace$ any $\partial^\alpha \phi \in \tfspace$. If $a \in C^\infty$ i.e. a doesn't have compact support, $a\phi \in \tfspace$ - its product with a function with compact support will also have compact support. Finally changes of variables, will also leave us within $\tfspace$ i.e. for an arbitrary vector $b \in \reals^N$ and an $N \times N$ matrix $A$, $\phi(Ax+b) \in \tfspace$.

Now we have a promising vector space, with useful properties for it's members such as compactness and boundedness. There is however one more thing we need to consider, which is the idea of convergence within the vector space.

\begin{definition}
    A sequence $\{\phi_i\}^\infty_{i=1} \in \tfspace $ is said to converge to zero if
    \begin{enumerate}
        \item There exists a compact set $K \subset \reals^N$ such that $\supp \phi_j \subset K$ for all $i=1,2,....$
        \item For each multi-index $\alpha$ the derivative $\partial^\alpha \phi_j$ converges to zero uniformly as $j \rightarrow \infty$. That is, for all $\alpha$, $\underset{x \in \reals^N}{\supp} |\partial^\alpha \phi_j(x)|\rightarrow 0$
    \end{enumerate}

    \label{def:convergence_of_tf}
\end{definition}


The set $\tfspace$ with the above convergence properties is called the \textbf{space of test functions}, and denoted by $\tfspaceD$. We remark that the convergence property is often denoted with respect to $\tfspaceD$ in the literature as,

\begin{eqnarray}
    \phi_N \overset{\tfspaceD}{\rightarrow} \phi
\end{eqnarray}

which further implies,

\begin{eqnarray}
    \phi_N - \phi \overset{\tfspaceD}{\rightarrow} 0
\end{eqnarray}

\subsection{Defining Distributions}

Consider two abstract sets $A$ and $B$, the map between them $f : A \rightarrow B$ defines a \textbf{functional}. The map $f$ is considered to be continuous if $a_n \overset{A}{\rightarrow} a$ implies that $f(a_n) \overset{B}{\rightarrow} f(a)$. Strictly, this is `sequential continuity'.

\begin{definition}
    The set of distributions, $\dist$, is the set of all \textbf{linear} and \textbf{ (sequentially) continuous} functionals that map $f : \tfspaceD \rightarrow \complexes$
\label{def:distribution}
\end{definition}

We see that the distributions are defined by mapping from the space of test functions to (potentially complex) numbers. This concept will allow us to generalise notions of differentiability.

If $f$ is a functional, then

\begin{enumerate}
    \item For each $\phi \in \tfspaceD$, the functional associates a number denoted by the following Bra-Ket notation $\langle f, \phi \rangle \in \complexes$. This is also described as the \textbf{action} of the functional.
    \item The functional is linear such that for $\alpha_1, \alpha_2 \in \complexes$ and $\phi_1, \phi_2 \in \tfspaceD$, $\langle f, \alpha_1\phi_1, \alpha_2\phi_2 \rangle = \alpha_1\langle f, \phi_1 \rangle + \alpha_2\langle f, \phi_2 \rangle $
    \item A distribution $f$ is called (sequntially) continuous on $\tfspaceD$ if $\langle f, \phi_k \rangle \rightarrow \langle f, \phi \rangle$ where $\phi_k \overset{\tfspaceD}{\rightarrow} \phi$ as $k \rightarrow \infty$
\end{enumerate}

Let us illustrate the concept of functionals which satisfy the definition of distributions by going through some examples.

\begin{enumerate}
    \item \textbf{Continuous functions as distributions}. Let $f \in C(\reals^N)$ and define a functional with the mapping $\tfspaceD(\reals^N) \rightarrow \complexes$ as $\langle f, \phi \rangle = \int_{\reals^N} f(x) \phi(x) dx < +\infty$ which is valid for $\forall \phi \in \tfspaceD$. The integral is linear, by inspection, so it remains to show that it is also continuous in the sense of sequential continuity. Consider a sequence of test functions $\phi_n \in \tfspaceD$ such that $\phi_n \rightarrow \phi$ in $\tfspaceD$, without loss of generality let us assume that $\phi = 0$ so we have to show now that the action $\langle f, \phi_n \rangle \rightarrow 0$. From the definition of convergence in $\tfspace$ (\ref{def:convergence_of_tf}), we know that there exists a compact set $K$ for which $\supp \phi_n \subset K \> \> (\forall n)$. Then, \[ |\langle f, \phi_n \rangle | = \left |\int_{\reals^N}f \phi_n dx \right | = \left |\int_K f \phi_n dx \right | \leq \sup_{x \in \reals^N} |\phi_n| \int_K |f| dx\]. From (\ref{def:convergence_of_tf}) we see that $\sup_{x \in \reals^N} |\phi_n| \rightarrow 0$ and the integral over $|f|$ in $K$ is finite due to the compactness of $K$, therefore $\langle f, \phi_n \rangle \rightarrow 0$ and the functional is sequentiallly continuous. A remark about notation, we've identified above a function $f$ with a \textit{functional} which we also denote by $f \in \dist$.
    \item \textbf{Heaviside function}. It therefore follows from above that a function defines a distribution if the following statement holds, \[ \int_K |f| dx < + \infty, \> \> \forall K \subset \reals^N \]

    Consider the Heaviside function in one dimension, \[ H(x) = \begin{cases}
        1, x > 0 \\
        0, x \leq 0
    \end{cases}\]
    Then we can define the action of the distribution generated by the Heaviside function as, \[ \langle H, \phi \rangle = \int_{-\infty}^{\infty} H(x) \phi(x) dx = \int_{0}^{\infty} \phi(x) dx, \> \> \forall \phi \in \tfspaceD \]

    Therefore we see that it also identifiable as a distribution.
\end{enumerate}

Before proceeding, we need the concept of regular distributions,

\begin{definition}[Regular Distribution]
A distribution $f \in \dist$ is called regular if $\exists f \in \lone$ such that \[ \langle f, \phi \rangle = \int_{\reals^N} f(x) \phi(x) dx, \> \> \forall \phi \in \tfspaceD\]
    \label{def:regular_dist}
\end{definition}

Here $\lone$ defines a function space where each member is `locally integrable', i.e. has a finite integral on every compact subset of its domain of definition. More formally, let $\Omega$ be an open set in $\reals^N$ and $f : \Omega \rightarrow \complexes$ if the following integral holds,
\begin{equation}
    \int_K |f| dx < + \infty
    \label{eq:l_one_loc}
\end{equation}

for all subsets $K \subset \Omega$, then $f \in \lone$. The 1 refers to the power of the absolute value in the integral. We then notice that the conditions for sequential continuity are satisfied if a functional is chosen from $\lone$.

\vspace{5pt}

As a final example of this section, consider the Dirac $\delta$-function, defined by the following action,

\begin{eqnarray}
\langle \delta, \phi \rangle = \phi(0), \> \> \forall \phi \in \tfspaceD(\reals^N)
    \label{eq:dirac}
\end{eqnarray}

The functional is clearly in $\lone$, thefore satisfies sequential continuity, with linearity obvious by inspection. Therefore we see that it satisfies the properties required of a distribution.

\subsection{Basic Operations on Distributions}

Here, we state some basic facts about operations on distributions largely without proof.

\subsubsection{Multiplication by a $C^\infty$ function}
For example, If $a \in C^\infty(\reals^N)$ and $f \in C(\reals^N)$ then $f \in \dist$ then,

\begin{equation}
    \langle af, \phi\rangle = \int_{\reals^N}(a(x)f(x))\phi(x)dx = \int_{\reals^N}f(x) (a(x)\phi(x))dx = \langle f, a\phi \rangle
\end{equation}

Implying that $a\phi \in \tfspace$. This identity can be extended to all distributions.

\begin{definition}
    If $a \in C^\infty$ and $f \in \dist$ then, $af \in \dist$ defined by \[
        \langle af, \phi \rangle = \langle f, a\phi \rangle, \>\> \forall \phi \in \tfspaceD\]
\end{definition}

One can check that the above does define a distribution through an example. Consider $f = \delta \in \dist$ and $a \in \tfspace$, then

\begin{eqnarray}
    \langle a\delta, \phi \rangle = \langle \delta, a \phi \rangle = a(0)\phi(0) = a(0) \langle \delta, \phi \rangle \> \> \forall \phi \in \tfspaceD
\end{eqnarray}

This implies that $a\delta = a(0) \delta$ and does define a distribution.

\subsubsection{Differentiation}

Differentiation for distributions uses a form of Green's identity. Consider the one dimensional case, $f \in C(\reals)$ and $\phi \in \tfspaceD(\reals)$ and has compact support, then

\begin{equation}
    \int_{-\infty}^{\infty} f'(x) \phi(x) dx = \int_a^b f'(x)\phi(x)dx = \left [ f \phi \right ]_a^b - \int_a^b f\phi' dx = -\int_a^b f\phi' dx
\end{equation}

The boundary term vanishes due to the compact support of $\phi$. Generalising the above identity for higher order derivatives, we see that,

\begin{equation}
    \int_{-\infty}^{\infty} \frac{d^m}{dx^m} f(x) \phi(x) dx = (-1)^m \int_{-infty}^{\infty} f(x) \frac{d^m}{dx^m}\phi(x) dx
\end{equation}

In the language of actions this goes to,

\begin{eqnarray}
    \langle \frac{d^m}{dx^m}f, \phi \rangle = \langle f, \frac{d^m}{dx^m} \phi \rangle
\end{eqnarray}

Furthermore, we state that this differentiated object defines a distribution too.

\begin{definition}
    Let $f \in \dist(\reals^N)$. Then for any multi-index $\alpha$ the distribution $\partial^\alpha f$ is defined to be, \[ \langle \partial^\alpha f, \phi \rangle = (-1)^{|\alpha|} \langle f, \partial^\alpha \phi \rangle, \> \> \forall \phi \in \tfspaceD(\reals^N) \]
    \label{def:differentiate_distribution}
\end{definition}

Let's consider some simple corollary examples,

\begin{enumerate}
    \item Consider a one dimensional problem in $\reals$ where $\delta \in \dist$. What is $\frac{d}{dx}\delta$? From the above definition, \[
        \langle \frac{d}{dx} \delta, \phi\rangle = - \langle \delta, \frac{d}{dx}\phi \rangle = -\phi'(0)\]
    \item Consider again a one dimension problem with the Heaviside function $H \in \dist$. What is $\frac{d}{dx}H$? Using the same procedure, \[
        \langle \frac{d}{dx}H, \phi \rangle = -\langle H, \frac{d}{dx} \phi \rangle = \int_0^\infty \frac{d\phi}{dx}dx = -[\phi]_0^\infty = \phi(0) = \langle \delta, \phi \rangle, \> \> \forall \phi \in \tfspaceD \]. This implies that $\frac{dH}{dx} = \delta$, in a distributional sense.
\end{enumerate}

\subsubsection{Change of Variables ($x = Ay + b$)}

Finally let's consider a linear transformation, corresponding to a change of variables. Here $A$ is a non-singular $N \times N$ matrix and $b \in \reals^N$. If $f \in C^\infty(\reals^N)$ and $\phi \in \tfspaceD(\reals^N)$, then

\begin{equation}
    \int_{\reals^N}f(Ay+b)\phi(y)dy = \int_{\reals^N}f(x)\phi(A^{-1}(x-b))\frac{1}{\text{det}(A)}dx
\end{equation}

This also defines a distribution, giving us our final definition in this section,

\begin{definition}
    Let $f \in \dist(\reals^N)$, with $A$ and $b$ as above, then $f(Ay+b) \in \dist$ is defined by \[\langle f(Ay+b), \phi(y)\rangle = \langle f(x), \phi(A^{-1}(x-b))\frac{1}{|A|}\rangle, \> \> \forall \phi \in \tfspaceD(\reals^N)\]
\end{definition}

\subsection{The Support of Distributions}

Distributions do not take `values' in a domain like a function would, but we define an equivalent statement by using their action. For example for a distribution $f$, the statement $f=0$ is read to mean that $\langle f, \phi \rangle = 0, \> \> \forall \phi \in \Omega, \> \> s.t. \> \> \supp \phi \subset \Omega$.

\begin{remark}
    For $f, g \in \dist$, then $f=g$ in $\Omega$ means that, \[ \langle f, \phi \rangle = \langle g, \phi \rangle, \> \> \forall \phi \in \tfspaceD(\Omega)\]
\end{remark}

We can now use this technology to define the support of a distribution.

\begin{definition}
    Let $f \in \dist(\reals^N)$. Then $\supp f$ is the complement of the set \[ O_f = \left \{ x \in \reals^n : f = 0 \> \> \text{on a neighbourhood of x}  \right \} \] This $O_f$ is known as the zero-set of $f$.
\end{definition}

\subsection{The Convergence of Distributions}

Recalling our sequential continuity condition, let $\{f_j\}_{j=1}^\infty$ be a sequence of distributions on $\reals^N$ where $f \in \dist(\reals^N)$.

\begin{definition}
    We say that $f_n$ converges to $f$ in $\dist$, and write $f_n \overset{\dist}{\rightarrow} f$, if \[ \langle f_n, \phi \rangle \rightarrow \langle f, \phi \rangle, \> \> \forall \phi \in \tfspaceD \] as $n \rightarrow \infty$
\end{definition}

Consider $f_n(x) = \frac{1}{n} \sin(nx)$. Clearly $f_n \in \lone(\reals)$, therefore $f_n$ defines a distribution, with the action

\begin{equation}
    \langle f_n, \phi \rangle = \int_{\reals} f_n(x) \phi(x) dx
\end{equation}

Indeed it's obvious that $f_n \rightarrow 0$ in the sense of $\dist$, noticing that

\begin{equation}
    | \langle f_n, \phi \rangle | = \left | \int_{\reals} \frac{1}{n} \sin(nx) \phi(x) dx\right | \leq \frac{1}{n} \left | \int_{\reals}\phi(x) \right |
\end{equation}

This leads to the following proposition. If $f_n \overset{\dist}{\rightarrow} f$, then $\partial^\alpha f_n \overset{\dist}{\rightarrow} \partial^\alpha f$ for all multi-indices $\alpha$. Consider a corollary example, where $g_n(x) = \cos(nx)$, then $g_n \overset{\dist}{\rightarrow} 0 $ as $\frac{d}{dx}(\frac{1}{n}\sin(nx)) = g_n$ and therefore we can apply the above result.

\vspace{5pt}

For a more involved example, consider $f \in \lone(\reals)$ and let $\supp f \in [-1, 1]$ with $\int_{-1}^1 f(x) dx = 1$ and consider the sequence defined by $f_k(x) = kf(kx)$ where $k=1,2,3...$ . Let us show that $f_k \overset{\dist}{\rightarrow} \dist$. Equivalently we can show that there is no difference between the actions of both functionals.

\begin{flalign}
    &\left | \langle f_k, \phi \rangle - \langle \delta, \phi \rangle \right | \\
    &= \left | \int_{-\infty}^\infty f_k(x)\phi(x)dx - \phi(0) \right | \\
    &= \left | \int_{-\infty}^\infty kf(kx)\phi(x)dx - \phi(0)\int_{-\infty}^\infty f(x)dx \right | \\
    &= \left | \int_{-1}^{1}f(x) ( \phi(\frac{x}{k}) - \phi(0) ) dx \right| \\
    &\leq \max_{x \in [-1, 1]} | \phi(\frac{x}{k}) - \phi(0)| = \max_{t \in [-1/k, 1/k]} | \phi(t) - \phi(0)| \rightarrow 0
\end{flalign}

These examples lead us to the final theorem of this section,

\begin{theorem}[Completeness of $\dist$]
    Consider the sequence of distributions $f_1,...,f_n,...$ such that for all $\phi \in \tfspaceD$ the sequence $\langle f_k, \phi \rangle$ converges as $k \rightarrow \infty$. Then the functional defined by, \[ \langle f, \phi \rangle = \lim_{k \rightarrow \infty} \langle f_k, \phi \rangle \] is linear and continuous, i.e it defines a distribution $f \in \dist$.
\end{theorem}

The intuitive interpretation of this theorem is basically that we can't leave the space of distributions by summing distributions.

\subsection{Equivalent Definition of Distributions}

\begin{notation}
    If $\Omega$ is an open set in $\reals^N$ and $K$ is a compact subset of $\Omega$ and $u \in C^m(\Omega)$ then \[ \| u \|_{C^m(K)} = \max_{x \in K, \> |\alpha| \leq m} |\partial^\alpha u| \]
\end{notation}

This allows us to write down our equivalent formulation of distributions.

\begin{definition}
    A linear functional $f$ on $\tfspaceD(\reals^N)$ is a distribution iff for all compact sets $K$ in $\reals^N$ there exist $C$ and $m$ such that,
    \[ |\langle f, \phi \rangle| \leq C \| \phi \|_{C^m(k)}\] For all $\phi \in \tfspaceD$ such that $\supp \phi \subset K$.
\end{definition}

Proving the reverse implication. We have the above definition, and we need to show that it satisfies sequential continuity. That is if $\phi_n \overset{\tfspaceD}{\rightarrow} \phi$, then $\langle f, \phi_n \rangle \overset{\dist}{\rightarrow} 0$

\vspace{5pt}

Proving the forward implication. Assume that $f \in \dist$, then let's prove by contradiction. Assume the alternative definition doesn't hold,

\begin{eqnarray}
    | \langle f, \phi_m \rangle | > m \| \phi_m \|_{C^m(K)}
\end{eqnarray}

Define $\psi_m = \frac{\phi_m}{m \| \phi_m \|_{C^m(K)}}$. Then $\psi_m \in \tfspaceD$, $\supp \psi_m \subset K$ and for any multi-index $\beta$ such that $m \geq |\beta|$, we have,

\begin{eqnarray}
    \| \psi_m \|_{C^{|\beta|}(K)} = \frac{\|\phi_m\|_{C^{|B|}(K)}}{m \|\phi_m\|_{C^m(K)}} \leq \frac{1}{m}
\end{eqnarray}

Consequently $\psi_m \overset{\tfspaceD}{\rightarrow} 0$. However, this contradicts our initial assumption.

\section{Fundamental Solution of Laplacian in $\reals^3$}

For a linear partial differential equation with linear operator $L$,

\begin{eqnarray}
    LF = \delta(x)
\end{eqnarray}

the fundamental solution, $F$,  is defined as that which yields the $\delta$-function up to a constant, and is therefore defined as the solution of the above equation.

Consider the Poisson problem,

\begin{eqnarray}
    \Delta u = f
    \label{eq:laplace}
\end{eqnarray}

Where the linear partial differential operator, the Laplace operator, is given by

\begin{eqnarray}
    \Delta = \sum_{i=1}^N \frac{\partial^2}{\partial x_i^2}
\end{eqnarray}

Let's check that the fundamental solution in $\reals^3$ is described by the following relation,

\begin{equation}
    \Delta \frac{1}{|x|} = -4\pi \delta(x)
\end{equation}

where as usual $|x| = \sqrt{x_1^2+x_2^2+x_3^2}$. We can check that the Laplacian of the fundamental solution is 0 in $\reals^3 \backslash \{ 0\}$ using our ordinary notions of derivative,

\begin{eqnarray}
    \frac{\partial}{\partial x_1} \frac{1}{|x|} = -\frac{x_1}{(x_1^2+x_2^2+x_3^2)^{\frac{3}{2}}}
\end{eqnarray}

and,

\begin{eqnarray}
    \frac{\partial^2}{\partial x_1 ^2} \frac{1}{|x|} = \frac{3x_1^2}{(x_1^2+x_2^2+x_3^2)^{\frac{5}{2}}}-\frac{1}{(x_1^2+x_2^2+x_3^2)^{\frac{3}{2}}}
\end{eqnarray}

from which the result follows. It's not really possible to define derivatives at the origin for our fundamental soltuion in the usual sense, however we can show that $1/|x| \in \lone$ - this would allow us to define it as a distribution with all of the useful properties that they have. To see that the statement is true, we simply have to observe that the integral,

\begin{eqnarray}
    \int_{K} \frac{1}{|x|} dx < +\infty
\end{eqnarray}

for all compact subsets $K \subset \reals^3$. If this is the case, then let's take a ball such that $K \subset B_R = \{ x | x < R\}$. Then,

\begin{flalign}
    \int_K |f| dx \leq \int_{B_R} |f| dx \leq \int_0^R \int_{S_r} |f| d\omega dr
\end{flalign}

where we've switched to using spherical coordinates defined by the surface of a sphere $\omega \in S_r = \{\ x: \sqrt{x_1^2 + x_2^2 + x_3^2}\}$, and the radial coordinate $r \in [0, R]$

\begin{flalign}
    &\int_0^R \frac{1}{r} \int_{S_r} d\omega dr \\
    &\int_0^R \frac{1}{r} r^2 dr = \int_0^R r dr < +\infty
\end{flalign}

This result extends to $\reals^N$ too, and allows to say that $1/|x| \in \lone$ and therefore that $1/|x| \in \dist$ and is a regular distribution.
Therefore, let's now take derivaitives of the fundamental solution in a distributional sense,

\begin{equation}
\langle \Delta \frac{1}{|x|}, \phi \rangle = \langle \frac{1}{|x|}, \Delta \phi \rangle = \int_{\reals^3} \frac{1}{|x|} \Delta \phi dx
\end{equation}

This is of course for any $\phi \in \tfspaceD(\reals^3)$. We note that the test functions have a finite support, $\supp \phi \subset B_R$, where we've drawn a ball around the compact subset $K$ in which they are supported to help our integral evaluation,

\begin{flalign}
 \int_{B_R} \frac{1}{|x|} \Delta \phi dx = \lim_{\epsilon \rightarrow 0} \int_{B_R \backslash \bar{B_\epsilon}} \frac{1}{|x|} \Delta \phi dx
\end{flalign}

Here we're taking the integral over the ball, and excluding an ever decreasing ball that is centered over the origin of radius $\epsilon$. Let's now integrate using Green's second identity,

\begin{flalign}
    \lim_{\epsilon \rightarrow 0} \left( \int_{B_R \backslash \bar{B}_\epsilon} \Delta \frac{1}{|x|} \phi dx + \oint_{S_\epsilon} \partial_n \phi \frac{1}{|x|} ds  - \oint_{S_\epsilon} \phi \partial_n \frac{1}{|x|} ds \right)
\end{flalign}

Here we've skipped some steps in the surface integrals, specifically we note that they will be zero over the outer surface due to the compact support of the test functions, and therefore exclude them from the integral. Furthermore, the first integral is zero by definition as we've shown that the Laplacian of the fundamental solution is 0 when excluding the origin.

\vspace{5pt}

We are then left with the two surface integrals,

\begin{flalign}
    \lim_{\epsilon \rightarrow 0} \left( \oint_{S_\epsilon} \partial_n \phi \frac{1}{|x|} ds  - \oint_{S_\epsilon} \phi \partial_n \frac{1}{|x|} ds \right)
\end{flalign}

Consider the first one of these,

\begin{flalign}
    \left | \oint_{S_\epsilon} \partial_n \phi \frac{1}{|x|} ds \right | &\leq \oint_{S_\epsilon} \max_{S_\epsilon}  | \nabla \phi| \frac{1}{|x|} ds \\
    & \leq \| \phi \|_{C^1(\reals^3)} \oint_{S_\epsilon} \frac{1}{|x|} ds \\
    & = \| \phi \|_{C^1(\reals^3)} \frac{1}{\epsilon} \oint_{S_\epsilon} ds = \| \phi \|_{C^1(\reals^3)} 4\pi \epsilon \overset{\epsilon \rightarrow 0}{\rightarrow} 0
\end{flalign}

Now the second, using the fact that the unit normal vector over the inner surface (pointing towards the origin) is $\hat{n}= -\frac{x}{|x|}$ and therefore that $\partial_n = -\partial_r$

\begin{flalign}
    &\oint_{S_\epsilon} \phi \partial_r \frac{1}{r} ds = - \oint_{S_\epsilon} \phi \frac{1}{r^2}ds = -\frac{1}{\epsilon^2} \oint_{S_\epsilon} \phi(x)ds \\
    & = -\frac{1}{\epsilon^2} \oint_{S_\epsilon} \phi(x) - \phi(0) ds - \frac{1}{\epsilon^2} \oint_{S_\epsilon} \phi(0) ds \\
    & = -\frac{1}{\epsilon^2} \oint_{S_\epsilon} \phi(x) - \phi(0) ds - 4\pi \phi(0)
\end{flalign}

All that remains is to show that the first integral converges to 0 and we'll have our result,

\begin{flalign}
    &\left | \frac{1}{\epsilon^2} \int_{S_\epsilon} \phi(x) - \phi(0) ds \right | \\
    & \leq \frac{1}{\epsilon^2} \int_{S_\epsilon} \left | \phi(x) - \phi(0)\right | ds \leq 4\pi \max_{x \in S_\epsilon} | \phi(x) - \phi(0) | \rightarrow 0
\end{flalign}

Therefore we see,

\begin{flalign}
    \langle \Delta \frac{1}{|x|}, \phi \rangle = -4\pi \phi(0) = -4\pi \langle\delta, \phi \rangle
\end{flalign}

for all $\phi \in \tfspaceD$, and that $\Delta \frac{1}{|x|} = -4\pi \delta$. Note that the fundamental solution is a family of solutions, and is not unique up to a constant.

The name `fundamental solution' seems very important, and as we shall see we will be able to write general solutions of PDEs using knowledge of them. However, in order to get to that point we need to have a few more operations on distributions up our sleeves.

\section{Direct Product of Distributions}

Let's take a series of steps which are as of yet poorly defined, but motivate the need for more operations on distributions. Consider again the Poisson problem in $\reals^3$, we now know the fundamental solution for this problem,

\begin{flalign}
E(x) = -\frac{1}{4\pi}\frac{1}{|x|}
\end{flalign}

Let's displace the solution by some fixed vector $y$, the Poisson problem then goes to,

\begin{flalign}
    \Delta_xE(x-y) = \delta(x-y)
\end{flalign}

Now, for our first poorly defined operation, multiplication by a distribution,

\begin{flalign}
    f(y)\Delta_xE(x-y) = f(y)\delta(x-y)
\end{flalign}

And then our second poorly defined operation, integration over the domain with respect to this fixed vector $y$

\begin{flalign}
    \int f(y)\Delta_xE(x-y) dy = \int f(y)\delta(x-y) dy
\end{flalign}

By linearity, and using the properties of the $\delta$-function,

\begin{flalign}
    \Delta_x \int f(y)E(x-y) dy = f(x)
\end{flalign}

We see that our Poisson problem is `solved' by,

\begin{flalign}
    u(x) = \int f(y)E(x-y) dy
\end{flalign}

meaning that we can derive a weak solution of the Poisson problem with knowledge of just the fundamental solution - a hint as to why these objects are so fundamental, they are in some way atomistically tied to a more general solution of the differential equation. As we shall see they can do even better than define weak solutions. However, in order to rigorously use this intuition, we need to first learn how distributions can be in a sense `multiplied' by each other. This motivates the desire to define a `direct product' between distributions, which generalise notions of multiplications to distributions.

Let us start with defining direct products with respect to test functions in $\reals^N$. Consider $f,g \in \tfspaceD(\reals^N)$ where the product $fg \in \tfspaceD(\reals^N)$. We define the tensor or direct product as $f \otimes g \in \tfspaceD(\reals^{N+N})$ in some `dual' space. As we can describe continuous functions as distributions, it is possible to write,

\begin{flalign}
    \langle f(x)g(y), \phi(x, y) \rangle &= \int_{\reals^{N+N}} f(x)g(y)\phi(x,y)dxdy \\
    &= \int_{\reals^N} f(x) \left( \int_{\reals^N} g(y) \phi(x, y) dy\right) dx \\
    &= \langle f(x), \langle g(y), \phi(x, y) \rangle_y \rangle_x
\end{flalign}

Now we can write down the definition of direct products between distributions,

\begin{definition}[Direct Product of Distributions]
    Let $f \in \dist(\reals^N)$ and $g \in \dist(\reals^M)$. Then $f \otimes g \in \dist(\reals^{N+M})$ defined by \[ \langle f \otimes g, \phi \rangle= \langle f(x), \langle g(y), \phi(x, y) \rangle \rangle \] valid for all $\phi \in \tfspaceD(\reals^{N+M})$
    \label{def:direct_product}
\end{definition}

If we check that the RHS of the above identity defines a linear and continuous functional, and therefore a valid distribution, then it is valid. Let's write it down in a lemma,

\begin{lemma}
    Let $g \in \dist(\reals^M)$ and $\phi \in \tfspaceD(\reals^{N+M})$ then $\psi(x) = \langle g(y), \phi(x, y) \rangle \in \tfspaceD(\reals^N)$ additionally \[ \partial^\alpha \psi(x) = \langle g(y), \partial^\alpha_x\phi(x, y)\rangle\] Furthermore, if $\phi_k \rightarrow 0$, then \[ \psi_k(x) = \langle g(y), \phi_k(x, y) \rangle \rightarrow 0\] in the space $\tfspaceD(\reals^N)$
\end{lemma}

All this is basically saying is that the inner action describes a valid test function for the outer action.

\vspace{5pt}

Let's begin by showing that $\psi$ is continuous. It is enough to show this in one direction, as the same technique can be used in turn to show it for other dimensions too. Let's fix $x_0 \in \reals^N$, and consider a sequence such that $x_k \rightarrow x_0$ with $x_k \in \reals^N$. The support of the test function can be seen to be fixed within some ball $\supp \phi(x_k, y) \subset B_b$ and from linearity, we know that for any multi-index $\beta$ that $\partial_y^\beta \phi(x_k, y) \rightarrow \partial_y^\beta\phi(x_0, y)$ uniformly in $y$. Which, due to the continuity of $g(y)$ gives,

\begin{eqnarray}
    \psi(x_k) = \langle g(y), \phi(x_k, y)\rangle \rightarrow \langle g(y), \phi(x_0, y) \rangle
\end{eqnarray}

Thus $\psi$ is sequentially continuous. All that remains is to show the two properties of the lemma.

To prove the first property, let's fix $x_0 \in \reals^N$ and take the derivative along just a single axis $e_1 = (1,0,0,...,0)$, then from the fundamental theorem of calculus,

\begin{flalign}
    \frac{\partial}{\partial x_1}\psi(x_0) &=\lim_{\epsilon \rightarrow 0} (\psi(x_0 + \epsilon e_1) - \psi(x_0)) \\
    & =\lim_{\epsilon \rightarrow 0} \left(\langle g(y), \frac{\psi(x_0 + \epsilon e_1) - \psi(x_0)}{\epsilon} \rangle \right)\\
    & = \lim_{\epsilon \rightarrow 0} \left( \langle g(y), \mu_\epsilon(y) \rangle \right)
\end{flalign}

We notice that $\mu_\epsilon(y) \rightarrow \frac{\partial \phi}{\partial x_1}(x_0, y)$ in $\tfspaceD(\reals^M)$, thus validating the first property in the lemma in a single dimension - this can be repeated for any dimension or set of dimensions.

\vspace{5pt}

Finally, let's show the second statement in the above lemma. If $\phi \rightarrow 0$ in $\tfspaceD(\reals^{N+M})$ then $\exists a, b$ such that $\supp \phi_k \subset B_a \times B_b$ then $\supp \psi_k(x) = \supp \psi(x_k, \cdot) \subset B_a$. We need to show that $\forall \alpha$

\begin{eqnarray}
    \sup_{x \in \reals^N} |\partial_x^\alpha \psi_k(x) | \rightarrow 0
\end{eqnarray}

Let's prove by contradiction. If it's not true, then $\exists \alpha_0, x_k, \epsilon_0 > 0$ such that,

\begin{eqnarray}
    |\partial_x^{\alpha_0} \psi_k(x) | \geq \epsilon_0
\end{eqnarray}

Consider a function $f_k(y) = (\partial_x^{\alpha_0}\phi_k)(x_k, y)$ for any multi-index $\beta$ we know that ,

\begin{eqnarray}
    \partial_x^{\alpha_0} \partial_y^\beta \phi_k (x, y) \rightarrow 0
\end{eqnarray}

uniformly in $x$ and $y$ simply from the peroperties of test functions. We can parametrize for a sequence $x_k$,

\begin{eqnarray}
    \partial_x^{\alpha_0} \partial_y^\beta \phi_k (x_k, y) \rightarrow 0
\end{eqnarray}

uniformly in $y$ as $k \rightarrow \infty$. By linearity, we can swap the order of the differential operators,

\begin{flalign}
    &\partial_y^\beta f_k(y) \rightarrow 0 \\
    & f_k \rightarrow 0
\end{flalign}

in the sense of $\tfspaceD(\reals^M)$. This implies that,

\begin{flalign}
    \langle g(y), f_k(y) \rangle \rightarrow 0
\end{flalign}

which leads to a contradiction, thereby proving our lemma.

\begin{corollary}[The Map A]
    $\phi \in \tfspaceD(\reals^{N+M})$ mapped by $A\phi = \psi(x) = \langle g(y), \phi(x, y) \rangle$ is linear and continuous from $\tfspaceD(\reals^{N+M})$ to $\tfspaceD({\reals^N})$.
\end{corollary}

\section{Convolution of Distributions}

\section{Fundamentality of Fundamental Solutions}

\section{The Fourier Transform}





\section{Scratch Pad}

\begin{problem}

\end{problem}

\end{document}
